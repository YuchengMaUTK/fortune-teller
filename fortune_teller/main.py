#!/usr/bin/env python3
"""
éœ„å  (Fortune Teller) - Main Application

A Python-based multi-system fortune telling application using LLMs.
"""
import os
import sys
import argparse
import logging
import json
import traceback
import time
import datetime
from typing import Dict, Any, List, Optional

# é™é»˜æ‰€æœ‰ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—ï¼Œå°†å®ƒä»¬ä»…è¾“å‡ºåˆ°æ–‡ä»¶
# è¿™æ®µä»£ç å¿…é¡»åœ¨å¯¼å…¥ä»»ä½•å…¶ä»–åº“ä¹‹å‰æ‰§è¡Œ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fortune_teller.log')
    ]
)

# ç§»é™¤æ‰€æœ‰å·²å­˜åœ¨çš„æ ¹æ—¥å¿—å¤„ç†å™¨ï¼Œé˜²æ­¢è¾“å‡ºåˆ°æ§åˆ¶å°
root_logger = logging.getLogger()
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)
root_logger.addHandler(logging.FileHandler('fortune_teller.log'))

# ç‰¹åˆ«å¤„ç†å¸¸è§çš„å™ªéŸ³åº“
for logger_name in ["boto3", "botocore", "urllib3", "s3transfer", 
                   "boto3.resources", "botocore.credentials"]:
    specific_logger = logging.getLogger(logger_name)
    specific_logger.setLevel(logging.ERROR)  # åªæ˜¾ç¤ºé”™è¯¯çº§åˆ«æ—¥å¿—
    specific_logger.propagate = False  # ä¸å‘ä¸Šä¼ æ’­æ—¥å¿—

from fortune_teller.core import BaseFortuneSystem, PluginManager, LLMConnector, ConfigManager
from fortune_teller.ui.colors import Colors
from fortune_teller.ui.display import (
    print_welcome_screen, print_llm_info, print_available_systems,
    get_user_inputs, display_eight_characters,
    print_reading_result, print_reading_result_streaming,
    print_followup_result, display_topic_menu,
    print_followup_result_streaming
)
from fortune_teller.ui.animation import LoadingAnimation

# åº”ç”¨ä¸“ç”¨çš„æ—¥å¿—é…ç½®
logger = logging.getLogger("FortuneTeller")


class FortuneTeller:
    """Main Fortune Teller application class."""
    
    def __init__(self, config_file: str = None):
        """
        Initialize the Fortune Teller application.
        
        Args:
            config_file: Path to configuration file
        """
        # Initialize configuration
        self.config_manager = ConfigManager(config_file)
        
        # Initialize plugin manager
        self.plugin_manager = PluginManager()
        
        # Initialize LLM connector
        llm_config = self.config_manager.get_config("llm")
        self.llm_connector = LLMConnector(llm_config)
        
        # Load plugins
        self.load_plugins()
        
        # Cache for processed data (used for follow-up questions)
        self._last_processed_data = {}
        
        logger.info("Fortune Teller initialized")
    
    def load_plugins(self) -> None:
        """Load and initialize fortune telling plugins."""
        num_loaded = self.plugin_manager.load_all_plugins()
        logger.info(f"Loaded {num_loaded} fortune telling plugins")
    
    def get_available_systems(self) -> List[Dict[str, Any]]:
        """
        Get a list of available fortune telling systems.
        
        Returns:
            List of fortune system information dictionaries
        """
        return self.plugin_manager.get_plugin_info_list()
    
    def perform_reading(
        self, 
        system_name: str, 
        inputs: Dict[str, Any],
        processed_data: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Perform a fortune telling reading.
        
        Args:
            system_name: Name of the fortune telling system to use
            inputs: User input data for the fortune system
            processed_data: Optional pre-processed data (to avoid re-processing)
            
        Returns:
            Reading results and metadata
            
        Raises:
            ValueError: If system is not found or inputs are invalid
        """
        # Get the requested fortune system
        fortune_system = self.plugin_manager.get_plugin(system_name)
        if not fortune_system:
            raise ValueError(f"æœªæ‰¾åˆ°å åœç³»ç»Ÿ: {system_name}")
        
        try:
            # Use provided processed data if available, otherwise process the inputs
            if processed_data is None:
                # Validate inputs
                validated_inputs = fortune_system.validate_input(inputs)
                
                # Process the data
                processed_data = fortune_system.process_data(validated_inputs)
            else:
                # If processed_data is provided, we use that directly
                validated_inputs = inputs
            
            # Save processed data for follow-up questions
            self._last_processed_data = {
                "system_name": system_name,
                "processed_data": processed_data,
                "inputs": validated_inputs
            }
            
            # Generate LLM prompts
            prompts = fortune_system.generate_llm_prompt(processed_data)
            
            # Get LLM response
            llm_response, metadata = self.llm_connector.generate_response(
                prompts["system_prompt"],
                prompts["user_prompt"]
            )
            
            # Format the result
            result = fortune_system.format_result(llm_response)
            
            # Add metadata to the result
            result["metadata"] = {
                "system_name": system_name,
                "timestamp": datetime.datetime.now().isoformat(),
                "llm_metadata": metadata,
                "inputs": {k: str(v) for k, v in inputs.items()}
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Error performing reading: {e}")
            raise ValueError(f"è§£è¯»é”™è¯¯: {str(e)}")
    
    def perform_followup_reading(
        self, 
        topic: str
    ) -> Dict[str, Any]:
        """
        Perform a follow-up reading on a specific topic.
        
        Args:
            topic: The specific topic to ask about (e.g., "æ€§æ ¼ç‰¹ç‚¹", "äº‹ä¸šè´¢è¿")
            
        Returns:
            Follow-up reading results
            
        Raises:
            ValueError: If there's no previous reading or if the topic is invalid
        """
        if not self._last_processed_data:
            raise ValueError("è¯·å…ˆè¿›è¡Œä¸»è¦è§£è¯»ï¼Œç„¶åå†è¯¢é—®å…·ä½“æ–¹é¢ã€‚")
        
        system_name = self._last_processed_data["system_name"]
        processed_data = self._last_processed_data["processed_data"]
        
        # Get the fortune system
        fortune_system = self.plugin_manager.get_plugin(system_name)
        if not fortune_system:
            raise ValueError(f"æœªæ‰¾åˆ°å åœç³»ç»Ÿ: {system_name}")
        
        # Define system-specific topics and prompts
        if system_name == "bazi":
            valid_topics = {
                "ğŸ§  æ€§æ ¼å‘½æ ¼": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„æ€§æ ¼ç‰¹ç‚¹ã€æ‰èƒ½å€¾å‘å’Œè¡Œä¸ºæ¨¡å¼ï¼Œä½¿ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ¯”å–»å’Œä¾‹å­ã€‚",
                "ğŸ’¼ äº‹ä¸šè´¢è¿": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„äº‹ä¸šå‘å±•ã€é€‚åˆè¡Œä¸šå’Œè´¢å¯Œæœºé‡ï¼Œç”¨é£è¶£å¹½é»˜çš„æ–¹å¼ç»™å‡ºå…·ä½“å»ºè®®ã€‚", 
                "â¤ï¸ å©šå§»æƒ…æ„Ÿ": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„æ„Ÿæƒ…çŠ¶å†µã€å©šå§»å€¾å‘å’Œæ¡ƒèŠ±è¿åŠ¿ï¼Œä»¥è¯™è°ä½†ä¸æ²¹è…»çš„æ–¹å¼æä¾›è§è§£ã€‚",
                "ğŸ§˜ å¥åº·å¯¿å…ƒ": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„å¥åº·çŠ¶å†µã€æ½œåœ¨é—®é¢˜å’Œå…»ç”Ÿå»ºè®®ï¼Œç”¨è½»æ¾æ–¹å¼ç‚¹å‡ºéœ€è¦æ³¨æ„çš„åœ°æ–¹ã€‚",
                "ğŸ”„ æµå¹´å¤§è¿": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººè¿‘æœŸå’Œæœªæ¥çš„è¿åŠ¿å˜åŒ–ã€å…³é”®æ—¶é—´ç‚¹ï¼Œç¥ç§˜è€Œåˆä¸å¤±é£è¶£åœ°å±•æœ›æœªæ¥ã€‚"
            }
        elif system_name == "tarot":
            valid_topics = {
                "ğŸŒŸ æ ¸å¿ƒå¯ç¤º": "è¯·è¯¦ç»†åˆ†ææ­¤å¡”ç½—ç‰Œé˜µçš„æ ¸å¿ƒä¿¡æ¯å’Œä¸»è¦å¯ç¤ºï¼Œç”¨æ·±å…¥è€Œé€šä¿—çš„è¯­è¨€æ­ç¤ºå…³é”®æ´è§ã€‚",
                "ğŸš¶ å½“å‰å¤„å¢ƒ": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…ç›®å‰æ‰€å¤„çš„çŠ¶å†µã€é¢ä¸´çš„ç¯å¢ƒå’Œå¿ƒç†çŠ¶æ€ï¼Œç”¨ç”ŸåŠ¨çš„æ¯”å–»å¸®åŠ©ç†è§£ã€‚", 
                "ğŸ§­ é˜»ç¢ä¸åŠ©åŠ›": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…å½“å‰é¢ä¸´çš„æŒ‘æˆ˜å’Œå¯åˆ©ç”¨çš„èµ„æºï¼Œæä¾›åˆ›é€ æ€§çš„æ€è·¯å’Œå®ç”¨å»ºè®®ã€‚",
                "ğŸ›¤ï¸ æ½œåœ¨è·¯å¾„": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…å¯èƒ½çš„å‘å±•æ–¹å‘å’Œé€‰æ‹©å»ºè®®ï¼Œä»¥æ¸©å’Œä½†æ˜ç¡®çš„æ–¹å¼æŒ‡å‡ºå„ç§å¯èƒ½æ€§ã€‚",
                "ğŸ’« ç²¾ç¥æˆé•¿": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…çš„å†…åœ¨æˆé•¿å’Œä¸ªäººè½¬å˜çš„æœºä¼šï¼Œç”¨å¯å‘æ€§çš„æ–¹å¼é¼“åŠ±è‡ªæˆ‘æ¢ç´¢ã€‚"
            }
        elif system_name == "zodiac":
            valid_topics = {
                "ğŸª æ˜Ÿç›˜è§£æ": "è¯·è¯¦ç»†åˆ†æè¿™ä»½æ˜Ÿç›˜çš„æ•´ä½“ç‰¹ç‚¹ã€è¡Œæ˜Ÿè§’åº¦åŠä¸»è¦å½±å“ï¼Œç”¨æ¸…æ™°æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šå¤æ‚çš„æ˜Ÿè±¡å…³ç³»ã€‚",
                "ğŸŒ  å®«ä½èƒ½é‡": "è¯·è¯¦ç»†åˆ†ææ˜Ÿç›˜ä¸­é‡è¦å®«ä½çš„èƒ½é‡åˆ†å¸ƒå’Œå½±å“ï¼Œç‰¹åˆ«å…³æ³¨ä¸Šå‡ã€ä¸­å¤©ã€ä¸‹é™å’Œå¤©åº•å®«ã€‚", 
                "ğŸ”„ å½“å‰è¡Œè¿": "è¯·è¯¦ç»†åˆ†æå½“å‰è¡Œæ˜Ÿè¿è¡Œå¯¹æ±‚æµ‹è€…çš„å½±å“ï¼ŒæŒ‡å‡ºå…³é”®çš„è¡Œæ˜Ÿç›¸ä½å’Œè¿‡å¢ƒç°è±¡ã€‚",
                "ğŸŒˆ å…ƒç´ å¹³è¡¡": "è¯·è¯¦ç»†åˆ†ææ˜Ÿç›˜ä¸­çš„å…ƒç´ ä¸èƒ½é‡åˆ†å¸ƒï¼Œè¯´æ˜ç«ã€åœŸã€é£ã€æ°´å››å…ƒç´ çš„å¹³è¡¡çŠ¶æ€ä¸ç¼ºå¤±æƒ…å†µã€‚",
                "âœ¨ æ˜Ÿåº§å¹´è¿": "è¯·è¯¦ç»†é¢„æµ‹æœªæ¥ä¸€å¹´å†…çš„æ˜Ÿè±¡å˜åŒ–åŠå…¶å¯¹æ±‚æµ‹è€…çš„å½±å“ï¼Œç”¨é¼“èˆäººå¿ƒçš„æ–¹å¼å±•æœ›æœªæ¥æœºé‡ã€‚"
            }
        else:
            # Default topics for any other system or fallback
            valid_topics = {
                "æ€§æ ¼ç‰¹ç‚¹": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„æ€§æ ¼ç‰¹ç‚¹ã€æ‰èƒ½å€¾å‘å’Œè¡Œä¸ºæ¨¡å¼ï¼Œä½¿ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ¯”å–»å’Œä¾‹å­ã€‚",
                "äº‹ä¸šè´¢è¿": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„äº‹ä¸šå‘å±•ã€é€‚åˆè¡Œä¸šå’Œè´¢å¯Œæœºé‡ï¼Œç”¨é£è¶£å¹½é»˜çš„æ–¹å¼ç»™å‡ºå…·ä½“å»ºè®®ã€‚", 
                "æ„Ÿæƒ…å§»ç¼˜": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„æ„Ÿæƒ…çŠ¶å†µã€å©šå§»å€¾å‘å’Œæ¡ƒèŠ±è¿åŠ¿ï¼Œä»¥è¯™è°ä½†ä¸æ²¹è…»çš„æ–¹å¼æä¾›è§è§£ã€‚",
                "å¥åº·æç¤º": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„å¥åº·çŠ¶å†µã€æ½œåœ¨é—®é¢˜å’Œå…»ç”Ÿå»ºè®®ï¼Œç”¨è½»æ¾æ–¹å¼ç‚¹å‡ºéœ€è¦æ³¨æ„çš„åœ°æ–¹ã€‚",
                "å¤§è¿æµå¹´": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººè¿‘æœŸå’Œæœªæ¥çš„è¿åŠ¿å˜åŒ–ã€å…³é”®æ—¶é—´ç‚¹ï¼Œç¥ç§˜è€Œåˆä¸å¤±é£è¶£åœ°å±•æœ›æœªæ¥ã€‚"
            }

        # Clean topic name (remove emoji if present)
        clean_topic = topic
        if any(emoji in topic for emoji in ["ğŸ§ ", "ğŸ’¼", "â¤ï¸", "ğŸ§˜", "ğŸ”„", "ğŸŒŸ", "ğŸš¶", "ğŸ§­", "ğŸ›¤ï¸", "ğŸ’«", "ğŸª", "ğŸŒ ", "ğŸŒˆ", "âœ¨", "ğŸ’¬"]):
            clean_topic = topic[2:].strip()  # Remove emoji and whitespace
            
        if topic not in valid_topics:
            topics_str = "ã€".join(list(valid_topics.keys()))
            raise ValueError(f"è¯·é€‰æ‹©æœ‰æ•ˆçš„è§£è¯»ä¸»é¢˜: {topics_str}")
            
        try:
            # Create a system prompt for the follow-up based on the system type
            if system_name == "bazi":
                system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½æ¥è‡ªä¸­å›½çš„å…«å­—å‘½ç†å­¦å¤§å¸ˆï¼Œå·²æœ‰30å¹´çš„å åœç»éªŒï¼Œæ€§æ ¼é£è¶£å¹½é»˜åˆä¸å¤±æ™ºæ…§ã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„å…«å­—å‘½ç†åˆ†æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[topic]}

è¯·ç¡®ä¿ä½ çš„å›ç­”æ—¢ä¸“ä¸šåˆé£è¶£ï¼Œåƒä¸€ä½å’Œè”¼å¯äº²çš„é•¿è¾ˆèŠå¤©ï¼Œè€Œä¸æ˜¯å†·å†°å†°çš„è¯´æ•™ã€‚è®©æ±‚æµ‹è€…æ„Ÿåˆ°è½»æ¾æ„‰å¿«ï¼ŒåŒæ—¶è·å¾—æœ‰ä»·å€¼çš„äººç”Ÿå¯ç¤ºã€‚

ä½ çš„åˆ†æåº”æ—¢æœ‰ä¸“ä¸šæ°´å‡†ï¼Œåˆå¯Œå«æƒ…è¶£ä»·å€¼ï¼Œå¯ä»¥å·§å¦™åœ°å¼•ç”¨ä¸€äº›è°šè¯­ã€å…¸æ•…æˆ–ç”Ÿæ´»å°æ•…äº‹æ¥å¸®åŠ©ç†è§£ã€‚
"""
            elif system_name == "tarot":
                system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½ç²¾é€šå¡”ç½—ç‰Œè§£è¯»çš„å¤§å¸ˆï¼Œæ‹¥æœ‰æ·±åšçš„ç¥ç§˜å­¦çŸ¥è¯†å’Œ20å¹´çš„å¡”ç½—ç‰Œè§£è¯»ç»éªŒã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„å¡”ç½—ç‰Œé˜µè§£æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[topic]}

ä½ çš„é£æ ¼ç¿æ™ºè€Œç¥ç§˜ï¼Œå……æ»¡ç€æ™ºæ…§ä¸æ´å¯ŸåŠ›ï¼Œä½†åŒæ—¶ä¹Ÿå¾ˆäº²å’Œï¼Œèƒ½ç”¨ç”ŸåŠ¨çš„è¯­è¨€å°†å¤æ‚çš„ç¬¦å·è±¡å¾è½¬åŒ–ä¸ºç›´è§‚çš„ç†è§£ã€‚

ä½ çš„è§£è¯»åº”å½“æ—¢æœ‰ä¸“ä¸šæ·±åº¦ï¼Œåˆæœ‰çµæ€§å¯å‘ï¼Œå¯ä»¥é€‚å½“å¼•ç”¨ä¸€äº›ç¥è¯ã€ä¼ è¯´æˆ–è±¡å¾å­¦çŸ¥è¯†æ¥ä¸°å¯Œåˆ†æã€‚
"""
            elif system_name == "zodiac":
                system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½ç²¾é€šè¥¿æ–¹å æ˜Ÿå­¦çš„ä¸“å®¶ï¼Œæœ‰ç€ä¸°å¯Œçš„å æ˜Ÿå’¨è¯¢ç»éªŒã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„æ˜Ÿç›˜åˆ†æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[topic]}

ä½ çš„é£æ ¼æ—¢æœ‰ä¸“ä¸šæ·±åº¦ï¼Œåˆä¸ä¹å¹½é»˜æ„Ÿï¼Œèƒ½å¤Ÿç”¨ç”ŸåŠ¨çš„æ¯”å–»å’Œå®ä¾‹è§£é‡Šå¤æ‚çš„æ˜Ÿè±¡ã€‚ä½ æ—¢å°Šé‡å æ˜Ÿå­¦çš„ä¼ ç»ŸçŸ¥è¯†ï¼Œ
åˆä¸ä¼šå®Œå…¨å†³å®šè®ºï¼Œè€Œæ˜¯å¼ºè°ƒæ¯ä¸ªäººéƒ½æœ‰è‡ªç”±æ„å¿—æ¥é€‰æ‹©å¦‚ä½•åº”å¯¹æ˜Ÿè±¡å½±å“ã€‚

ä½ çš„è§£è¯»åº”å½“å¹³è¡¡ã€å®¢è§‚ï¼Œé¿å…è¿‡äºç»å¯¹åŒ–çš„é¢„æµ‹ã€‚æä¾›å®ç”¨çš„å»ºè®®å’Œè§‚ç‚¹ï¼Œå¸®åŠ©å’¨è¯¢è€…æ›´å¥½åœ°ç†è§£è‡ªå·±å’Œå½“å‰çš„èƒ½é‡å½±å“ã€‚
"""
            else:
                # Default generic prompt
                system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½æ¥è‡ªä¸­å›½çš„å‘½ç†å­¦å¤§å¸ˆï¼Œå·²æœ‰30å¹´çš„å åœç»éªŒï¼Œæ€§æ ¼é£è¶£å¹½é»˜åˆä¸å¤±æ™ºæ…§ã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„å‘½ç†åˆ†æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[topic]}

è¯·ç¡®ä¿ä½ çš„å›ç­”æ—¢ä¸“ä¸šåˆé£è¶£ï¼Œåƒä¸€ä½å’Œè”¼å¯äº²çš„é•¿è¾ˆèŠå¤©ï¼Œè€Œä¸æ˜¯å†·å†°å†°çš„è¯´æ•™ã€‚è®©æ±‚æµ‹è€…æ„Ÿåˆ°è½»æ¾æ„‰å¿«ï¼ŒåŒæ—¶è·å¾—æœ‰ä»·å€¼çš„äººç”Ÿå¯ç¤ºã€‚

ä½ çš„åˆ†æåº”æ—¢æœ‰ä¸“ä¸šæ°´å‡†ï¼Œåˆå¯Œå«æƒ…è¶£ä»·å€¼ï¼Œå¯ä»¥å·§å¦™åœ°å¼•ç”¨ä¸€äº›è°šè¯­ã€å…¸æ•…æˆ–ç”Ÿæ´»å°æ•…äº‹æ¥å¸®åŠ©ç†è§£ã€‚
"""
            
            # Create a user prompt with the processed data and topic based on the system type
            if system_name == "bazi":
                user_prompt = f"""åŸºäºåˆšæ‰çš„å…«å­—åˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚

å››æŸ±å…«å­—ï¼š
{processed_data["four_pillars"]["year"]} {processed_data["four_pillars"]["month"]} {processed_data["four_pillars"]["day"]} {processed_data["four_pillars"]["hour"]}

æ€§åˆ«: {processed_data["gender"]}
å‡ºç”Ÿæ—¥æœŸ: {processed_data["birth_date"]}
å‡ºç”Ÿæ—¶é—´: {processed_data["birth_time"]}

æ—¥ä¸»: {processed_data["day_master"]["character"]} ({processed_data["day_master"]["element"]})
æœ€å¼ºäº”è¡Œ: {processed_data["elements"]["strongest"]}
æœ€å¼±äº”è¡Œ: {processed_data["elements"]["weakest"]}

è¯·æä¾›è¯¦ç»†è€Œæœ‰è¶£çš„"{clean_topic}"åˆ†æã€‚"""
            elif system_name == "tarot":
                # Reconstruct tarot reading summary from processed data
                card_info = ""
                if "reading" in processed_data:
                    for i, card in enumerate(processed_data["reading"], 1):
                        position = card.get("position", f"ä½ç½®{i}")
                        card_name = card.get("card", "")
                        orientation = card.get("orientation", "")
                        card_info += f"{position}: {card_name} ({orientation})\n"
                
                user_prompt = f"""åŸºäºåˆšæ‰çš„å¡”ç½—ç‰Œé˜µåˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚

å¡”ç½—ç‰Œé˜µï¼š{processed_data.get("spread", {}).get("name", "æœªçŸ¥ç‰Œé˜µ")}
é—®é¢˜ï¼š{processed_data.get("question", "æœªçŸ¥")}
é¢†åŸŸï¼š{processed_data.get("focus_area", "æœªçŸ¥")}

æŠ½å–çš„ç‰Œï¼š
{card_info}

è¯·æä¾›è¯¦ç»†è€Œæœ‰æ·±åº¦çš„"{clean_topic}"åˆ†æã€‚"""
            elif system_name == "zodiac":
                # Construct zodiac reading summary from processed data
                sign_info = processed_data.get("zodiac_sign", {})
                
                user_prompt = f"""åŸºäºåˆšæ‰çš„æ˜Ÿç›˜åˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚

å¤ªé˜³æ˜Ÿåº§ï¼š{sign_info.get("name", "æœªçŸ¥")} ({sign_info.get("english", "Unknown")})
æœˆäº®æ˜Ÿåº§ï¼š{processed_data.get("moon_sign", "æœªçŸ¥")}
ä¸Šå‡æ˜Ÿåº§ï¼š{processed_data.get("rising_sign", "æœªçŸ¥")}

å…ƒç´ ï¼š{sign_info.get("element", "æœªçŸ¥")}
å“è´¨ï¼š{sign_info.get("quality", "æœªçŸ¥")}
ä¸»å®°æ˜Ÿï¼š{sign_info.get("ruler", "æœªçŸ¥")}

å…³æ³¨é¢†åŸŸï¼š{processed_data.get("question_area", "æœªçŸ¥")}

è¯·æä¾›è¯¦ç»†è€Œæœ‰æ´è§çš„"{clean_topic}"åˆ†æã€‚"""
            else:
                # Generic prompt as fallback
                user_prompt = f"""åŸºäºåˆšæ‰çš„å‘½ç†åˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚
                
è¯·æä¾›è¯¦ç»†è€Œæœ‰ä¸“ä¸šçš„"{clean_topic}"åˆ†æã€‚"""
            
            # Get LLM response for the follow-up
            llm_response, metadata = self.llm_connector.generate_response(
                system_prompt,
                user_prompt
            )
            
            # Format the result for the follow-up
            result = {
                "analysis": {
                    topic.replace("ğŸ§  ", "").replace("ğŸ’¼ ", "").replace("â¤ï¸ ", "").replace("ğŸ§˜ ", "").replace("ğŸ”„ ", "")
                    .replace("ğŸŒŸ ", "").replace("ğŸš¶ ", "").replace("ğŸ§­ ", "").replace("ğŸ›¤ï¸ ", "").replace("ğŸ’« ", "")
                    .replace("ğŸª ", "").replace("ğŸŒ  ", "").replace("ğŸŒˆ ", "").replace("âœ¨ ", "").replace("ğŸ’¬ ", "")
                    .strip(): llm_response.strip()
                },
                "full_text": llm_response,
                "format_version": "1.0",
                "metadata": {
                    "system_name": system_name,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "topic": topic
                }
            }
            
            return result
            
        except Exception as e:
            logger.error(f"é”™è¯¯ç”Ÿæˆ'{topic}'çš„è§£è¯»: {e}")
            raise ValueError(f"è§£è¯»é”™è¯¯: {str(e)}")
    
    def save_reading(self, reading: Dict[str, Any], filename: str = None) -> str:
        """
        Save a reading to a file.
        
        Args:
            reading: Reading data to save
            filename: Filename to save to, or None for automatic name
            
        Returns:
            Path of the saved file
        """
        if not filename:
            # Generate a filename based on the system and timestamp
            system = reading["metadata"]["system_name"]
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"reading_{system}_{timestamp}.json"
        
        # Ensure directory exists
        os.makedirs(os.path.dirname(os.path.abspath(filename)), exist_ok=True)
        
        # Save the reading
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(reading, f, ensure_ascii=False, indent=2)
        
        return os.path.abspath(filename)


def run_interactive_menu(fortune_teller, args):
    """
    Run the interactive command-line interface.
    
    Args:
        fortune_teller: FortuneTeller instance
        args: Parsed command-line arguments
    """
    try:
        first_run = True  # æ·»åŠ æ ‡å¿—ä½æ§åˆ¶æ¬¢è¿ç”»é¢æ˜¾ç¤º
        
        while True:  # Main loop to allow returning to the main menu
            # ä»…åœ¨é¦–æ¬¡è¿è¡Œæ—¶æ˜¾ç¤ºæ¬¢è¿ç”»é¢
            if first_run:
                print_welcome_screen()
                first_run = False  # é‡ç½®æ ‡å¿—ä½
            else:
                # æ˜¾ç¤ºç®€åŒ–çš„æ ‡é¢˜ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„æ¬¢è¿ç”»é¢
                print(f"\n{Colors.BOLD}{Colors.YELLOW}âœ¨ éœ„å å‘½ç†ç³»ç»Ÿ âœ¨{Colors.ENDC}")
                print(f"{Colors.CYAN}" + "=" * 60 + f"{Colors.ENDC}")
        
            
            # Get available systems
            available_systems = fortune_teller.get_available_systems()
            if not available_systems:
                print(f"{Colors.RED}é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„å åœç³»ç»Ÿ{Colors.ENDC}")
                return
            
            # Select a system
            system = None
            if args.system:
                # Find the specified system
                for sys in available_systems:
                    if sys["name"] == args.system:
                        system = fortune_teller.plugin_manager.get_plugin(args.system)
                        break
                
                if not system:
                    print(f"é”™è¯¯: æœªæ‰¾åˆ°å åœç³»ç»Ÿ '{args.system}'")
                    print_available_systems(available_systems)
                    return
            else:
                # Let the user choose a system
                print_available_systems(available_systems)
                while True:
                    try:
                        choice = int(input("è¯·é€‰æ‹©ä¸€ä¸ªå åœç³»ç»Ÿ (è¾“å…¥åºå·): "))
                        if 1 <= choice <= len(available_systems):
                            system_info = available_systems[choice - 1]
                            system = fortune_teller.plugin_manager.get_plugin(system_info["name"])
                            break
                        else:
                            print(f"è¯·è¾“å…¥1åˆ°{len(available_systems)}ä¹‹é—´çš„æ•°å­—")
                    except ValueError:
                        print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            
            # Get user inputs for the selected system
            inputs = get_user_inputs(system)
            
            # Process the user input to get the processed data
            try:
                validated_inputs = system.validate_input(inputs)
                processed_data = system.process_data(validated_inputs)
                
                # Display the processed data using the system-specific display method
                system.display_processed_data(processed_data)
                
                # Store the processed data in the fortune teller's cache to prevent re-drawing cards
                # This is crucial for tarot readings to ensure consistency between displayed and interpreted cards
                fortune_teller._last_processed_data = {
                    "system_name": system.name,
                    "processed_data": processed_data,
                    "inputs": validated_inputs
                }
                
                # Confirm to proceed
                input(f"\n{Colors.CYAN}æŒ‰å›è½¦é”®ç»§ç»­ç”Ÿæˆè¯¦ç»†è§£è¯»...{Colors.ENDC}")
                
            except Exception as e:
                print(f"{Colors.RED}å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}{Colors.ENDC}")
                continue  # Return to the main menu instead of exiting
            
            # Generate LLM prompts from the stored processed data
            prompts = system.generate_llm_prompt(processed_data)
            
            # Save the result if output specified
            output_path = None
            if args.output:
                # Create empty result structure to be populated
                empty_result = {
                    "metadata": {
                        "system_name": system.name,
                        "timestamp": datetime.datetime.now().isoformat(),
                        "inputs": {k: str(v) for k, v in inputs.items()}
                    }
                }
                output_path = fortune_teller.save_reading(empty_result, args.output)
            
            # Show loading animation for non-streaming mode
            animation = LoadingAnimation("æ­£åœ¨è¿æ¥å¤§è¯­è¨€æ¨¡å‹ï¼Œè§£æå‘½ç†")
            animation.start()

            try:
                # Define handlers for streaming and non-streaming responses
                def handle_streaming(response_generator, start_time):
                    """æµå¼è¾“å‡ºå¤„ç†å‡½æ•°"""
                    nonlocal animation
                    # Stop animation before streaming output begins
                    animation.stop()
                    
                    return print_reading_result_streaming(
                        response_generator, 
                        output_path,
                        start_time=start_time
                    )
                
                def handle_standard(response, metadata):
                    """æ ‡å‡†è¾“å‡ºå¤„ç†å‡½æ•°"""
                    nonlocal animation, system
                    # Format the result
                    result = system.format_result(response)
                    
                    # Add metadata to the result
                    result["metadata"] = {
                        "system_name": system.name,
                        "timestamp": datetime.datetime.now().isoformat(),
                        "llm_metadata": metadata,
                        "inputs": {k: str(v) for k, v in inputs.items()}
                    }
                    
                    # Stop the loading animation
                    animation.stop()
                    
                    # Save the result if output specified
                    nonlocal output_path
                    if args.output:
                        output_path = fortune_teller.save_reading(result, args.output)
                    
                    # Display the result using standard method
                    print_reading_result(result, output_path)
                    return response
                
                # Use unified API for response generation
                complete_response = fortune_teller.llm_connector.generate_best_response(
                    prompts["system_prompt"],
                    prompts["user_prompt"],
                    streaming_handler=handle_streaming,
                    non_streaming_handler=handle_standard
                )
                
                # Interactive followup menu
                if not run_followup_menu(fortune_teller):
                    break  # Exit if user doesn't want to return to main menu
                
            except KeyboardInterrupt:
                # Handle user interruption
                animation.stop()
                print(f"\n\n{Colors.RED}å·²å–æ¶ˆè§£è¯»ç”Ÿæˆã€‚{Colors.ENDC}")
                continue  # Return to the main menu
                
            except Exception as e:
                animation.stop()
                print(f"{Colors.RED}è§£è¯»å‡ºé”™: {str(e)}{Colors.ENDC}")
                continue  # Return to the main menu
    
    except KeyboardInterrupt:
        print(f"\n\n{Colors.YELLOW}æ„Ÿè°¢ä½¿ç”¨éœ„å å‘½ç†ç³»ç»Ÿï¼Œå†è§ï¼{Colors.ENDC}")
        return
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        traceback.print_exc()


def run_chat_mode(fortune_teller, system_name=None):
    """
    Run an interactive chat mode with the LLM as the fortune teller.
    
    Args:
        fortune_teller: FortuneTeller instance
        system_name: Optional name of the fortune system to use for chat
        
    Returns:
        True if user wants to return to main menu, False to exit
    """
    # Use the appropriate system based on what we're using
    if system_name:
        # Get the specific fortune system
        fortune_system = fortune_teller.plugin_manager.get_plugin(system_name)
        system_display_name = fortune_system.display_name
    elif fortune_teller._last_processed_data:
        # Use the last used system if available
        system_name = fortune_teller._last_processed_data["system_name"]
        fortune_system = fortune_teller.plugin_manager.get_plugin(system_name)
        system_display_name = fortune_system.display_name
    else:
        # Default to generic system
        fortune_system = None
        system_display_name = "å‘½ç†å¸ˆ"
    
    # Display welcome message
    print(f"\n{Colors.BOLD}{Colors.YELLOW}âœ¨ ä¸éœ„å {system_display_name}èŠå¤© âœ¨{Colors.ENDC}")
    print(f"{Colors.CYAN}" + "=" * 60 + f"{Colors.ENDC}\n")
    print(f"æ‚¨å¯ä»¥å‘éœ„å {system_display_name}è¯¢é—®ä»»ä½•å…³äºå‘½ç†ã€è¿åŠ¿æˆ–ç”Ÿæ´»çš„é—®é¢˜ã€‚")
    print(f"{system_display_name}å°†ä»¥çµæ´»å¹½é»˜çš„æ–¹å¼ä¸æ‚¨äº¤æµï¼Œåˆ†äº«æ™ºæ…§ä¸è§è§£ã€‚")
    print(f"è¾“å…¥ {Colors.GREEN}exit{Colors.ENDC} æˆ– {Colors.GREEN}é€€å‡º{Colors.ENDC} è¿”å›ä¸»èœå•ã€‚\n")
    
    # Get system prompt from the fortune system or use default if not available
    if fortune_system:
        system_prompt = fortune_system.get_chat_system_prompt()
    else:
        system_prompt = """ä½ æ˜¯"éœ„å "å‘½ç†å¤§å¸ˆï¼Œä¸€ä½æ¥è‡ªä¸­å›½çš„å‘½ç†å­¦ä¸“å®¶ï¼Œå·²æœ‰30å¹´çš„å åœç»éªŒï¼Œæ€§æ ¼é£è¶£å¹½é»˜åˆä¸å¤±æ™ºæ…§ã€‚
ç°åœ¨ä½ æ­£åœ¨ä¸æ±‚æµ‹è€…è¿›è¡Œè½»æ¾çš„èŠå¤©äº’åŠ¨ã€‚ä½ å¯ä»¥è°ˆè®ºå‘½ç†å­¦çŸ¥è¯†ã€å›ç­”å…³äºè¿åŠ¿çš„é—®é¢˜ï¼Œ
ä¹Ÿå¯ä»¥èŠä¸€äº›æ—¥å¸¸è¯é¢˜ï¼Œä½†å§‹ç»ˆä¿æŒç€å‘½ç†å¸ˆçš„è§’è‰²å’Œè§†è§’ã€‚
ç”¨ç”ŸåŠ¨æœ‰è¶£çš„è¯­è¨€è¡¨è¾¾ï¼Œå¶å°”å¼•ç”¨å¤è¯—è¯æˆ–ä¿çš®è¯ï¼Œè®©è°ˆè¯å……æ»¡è¶£å‘³æ€§ã€‚
è®©æ±‚æµ‹è€…æ„Ÿè§‰æ˜¯åœ¨å’Œä¸€ä½ç¿æ™ºè€Œäº²åˆ‡çš„è€æœ‹å‹èŠå¤©ã€‚

å¯¹è¯åº”ç®€æ´ç²¾ç‚¼ï¼Œå›ç­”æ§åˆ¶åœ¨200å­—ä»¥å†…ï¼Œä¿æŒå¹½é»˜é£è¶£çš„è¯­æ°”ã€‚
"""
    
    user_prompt = "è¯·å‘ç”¨æˆ·æ‰“æ‹›å‘¼ï¼Œè‡ªæˆ‘ä»‹ç»ï¼Œå¹¶è¯¢é—®ä»–ä»¬æƒ³äº†è§£ä»€ä¹ˆã€‚"
    
    try:
        # Show loading animation
        animation = LoadingAnimation("éœ„å å‘½ç†å¸ˆæ­£åœ¨æ²‰æ€")
        animation.start()
        
        # Get initial greeting from LLM
        response, _ = fortune_teller.llm_connector.generate_response(system_prompt, user_prompt)
        
        # Stop animation
        animation.stop()
        
        # Display the greeting
        print(f"\n{Colors.GREEN}éœ„å : {Colors.ENDC}{response.strip()}\n")
        
        # Chat loop
        chat_context = []  # Store recent chat history
        while True:
            # Get user input
            user_input = input(f"{Colors.YELLOW}æ‚¨: {Colors.ENDC}")
            
            # Check for exit command
            if user_input.lower().strip() in ["exit", "quit", "é€€å‡º", "q"]:
                print(f"\n{Colors.CYAN}éœ„å å‘½ç†å¸ˆå‘æ‚¨æŒ¥æ‰‹å‘Šåˆ«ï¼Œæ¬¢è¿éšæ—¶å›æ¥ç»§ç»­èŠå¤©ï¼{Colors.ENDC}")
                return True
            
            if not user_input.strip():
                continue
            
            # Add to chat context
            chat_context.append(f"ç”¨æˆ·: {user_input}")
            
            # Limit context length
            if len(chat_context) > 5:
                chat_context = chat_context[-5:]
            
            # Create prompt with context
            context_prompt = "\n".join(chat_context)
            chat_prompt = f"""æ±‚æµ‹è€…åˆšåˆšè¯´: "{user_input}"

åŸºäºä»¥å‰çš„å¯¹è¯å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰ï¼š
{context_prompt}

è¯·ä»¥éœ„å å‘½ç†å¸ˆçš„èº«ä»½å›åº”ã€‚è®°å¾—ä¿æŒå¹½é»˜é£è¶£ï¼Œå¹¶æ§åˆ¶å›å¤åœ¨200å­—ä»¥å†…ã€‚"""
            
                
            try:
                # å®šä¹‰èŠå¤©çš„å¤„ç†å‡½æ•°
                def handle_chat_streaming(response_generator, start_time, thinking_anim):
                    """èŠå¤©æµå¼è¾“å‡ºå¤„ç†å‡½æ•°"""
                    nonlocal animation, chat_context
                    # Stop main animation (the loading one)
                    animation.stop()
                    
                    # æ˜¾ç¤ºæµå¼ç»“æœå¹¶æµ‹é‡é¦–ä¸ªå—å»¶è¿Ÿ
                    complete_response = ""
                    chunk_count = 0
                    first_chunk_time = None
                    
                    for chunk in response_generator:
                        # è®°å½•é¦–ä¸ªå—æ—¶é—´
                        if chunk_count == 0:
                            # åœæ­¢æ€è€ƒåŠ¨ç”»ï¼Œå®ƒä¼šè‡ªåŠ¨æ˜¾ç¤ºéœ„å : å‰ç¼€
                            thinking_anim.stop()
                            
                            first_chunk_time = time.time()
                            latency = first_chunk_time - start_time
                            logger.info(f"èŠå¤©é¦–ä¸ªå—å»¶è¿Ÿ: {latency:.3f}ç§’")
                        
                        # è·³è¿‡ç©ºå—
                        if not chunk or chunk.strip() == "":
                            continue
                            
                        chunk_count += 1
                        
                        # æ‰“å°å—å¹¶åˆ·æ–°
                        sys.stdout.write(chunk)
                        sys.stdout.flush()
                        
                        # æ·»åŠ åˆ°å®Œæ•´å“åº”
                        complete_response += chunk
                        
                        # é€‚å½“å»¶è¿Ÿä»¥ç¡®ä¿æ›´æµç•…çš„é˜…è¯»ä½“éªŒ
                        time.sleep(0.05)  # ä»0.01å¢åŠ åˆ°0.05ï¼Œä½¿è¾“å‡ºæ›´å¹³æ»‘
                    
                    # æµå¼å“åº”åæ·»åŠ æ¢è¡Œ
                    print("\n")
                    return complete_response
                
                def handle_chat_standard(response, metadata, thinking_anim):
                    """èŠå¤©æ ‡å‡†è¾“å‡ºå¤„ç†å‡½æ•°"""
                    nonlocal animation
                    # åœæ­¢æ‰€æœ‰åŠ¨ç”»
                    animation.stop()
                    thinking_anim.stop()
                    
                    # æ˜¾ç¤ºå“åº” (æ€è€ƒåŠ¨ç”»åœæ­¢åä¼šè‡ªåŠ¨æ˜¾ç¤ºéœ„å : å‰ç¼€)
                    print(f"{response.strip()}\n")
                    return response
                
                # åœ¨è°ƒç”¨å‰å¯¼å…¥å¹¶åˆå§‹åŒ–æ€è€ƒåŠ¨ç”»
                from fortune_teller.ui.thinking_animation import ChatThinkingAnimation
                
                # å…ˆå®Œå…¨åœæ­¢ä¸»åŠ¨ç”»ï¼Œç¡®ä¿å®ƒä¸å†æ˜¾ç¤ºä»»ä½•å†…å®¹
                animation.stop()
                
                # æ¸…é™¤ç°æœ‰è¾“å‡ºè¡Œï¼Œç¡®ä¿æ²¡æœ‰æ®‹ç•™åŠ¨ç”»æ–‡æœ¬
                sys.stdout.write("\r" + " " * 60 + "\r") 
                sys.stdout.flush()
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿ä¸»åŠ¨ç”»å®Œå…¨åœæ­¢
                time.sleep(0.1)
                
                # æ˜¾ç¤ºå³æ—¶åé¦ˆï¼ˆåœ¨APIè°ƒç”¨å‰ï¼‰
                thinking_animation = ChatThinkingAnimation(prefix="")
                print(f"\n{Colors.GREEN}éœ„å : {Colors.ENDC}", end="", flush=True)
                thinking_animation.start()
                
                # ä½¿ç”¨ç»Ÿä¸€çš„APIç”Ÿæˆå“åº”
                response = fortune_teller.llm_connector.generate_best_response(
                    system_prompt, 
                    chat_prompt,
                    streaming_handler=lambda gen, st: handle_chat_streaming(gen, st, thinking_animation),
                    non_streaming_handler=lambda resp, meta: handle_chat_standard(resp, meta, thinking_animation)
                )
                
                # å°†å“åº”æ·»åŠ åˆ°èŠå¤©ä¸Šä¸‹æ–‡
                chat_context.append(f"éœ„å : {response.strip()}")
                
            except Exception as e:
                animation.stop()
                print(f"\n{Colors.RED}éœ„å æ€è€ƒè¿‡åº¦èµ°ç¥äº†: {e}{Colors.ENDC}")
                
    except KeyboardInterrupt:
        print(f"\n\n{Colors.CYAN}éœ„å å‘½ç†å¸ˆå‘æ‚¨æŒ¥æ‰‹å‘Šåˆ«ï¼Œæ¬¢è¿éšæ—¶å›æ¥ç»§ç»­èŠå¤©ï¼{Colors.ENDC}")
        return True
    
    return True


def run_followup_menu(fortune_teller):
    """
    Run the interactive follow-up menu.
    
    Args:
        fortune_teller: FortuneTeller instance
        
    Returns:
        True if user wants to return to main menu, False to exit
    """
    while True:
        # Move topic generation inside loop to regenerate each time
        # Determine which system is being used
        if not fortune_teller._last_processed_data:
            # Fallback to generic topics if no previous reading
            valid_topics = ["æ€§æ ¼ç‰¹ç‚¹", "äº‹ä¸šè´¢è¿", "æ„Ÿæƒ…å§»ç¼˜", "å¥åº·æç¤º", "å¤§è¿æµå¹´", "ä¸éœ„å èŠå¤©"]
        else:
            system_name = fortune_teller._last_processed_data["system_name"]
            
            if system_name == "bazi":
                valid_topics = [
                    "ğŸ§  æ€§æ ¼å‘½æ ¼", "ğŸ’¼ äº‹ä¸šè´¢è¿", "â¤ï¸ å©šå§»æƒ…æ„Ÿ", 
                    "ğŸ§˜ å¥åº·å¯¿å…ƒ", "ğŸ”„ æµå¹´å¤§è¿"
                ]
            elif system_name == "tarot":
                valid_topics = [
                    "ğŸŒŸ æ ¸å¿ƒå¯ç¤º", "ğŸš¶ å½“å‰å¤„å¢ƒ", "ğŸ§­ é˜»ç¢ä¸åŠ©åŠ›", 
                    "ğŸ›¤ï¸ æ½œåœ¨è·¯å¾„", "ğŸ’« ç²¾ç¥æˆé•¿"
                ]
            elif system_name == "zodiac":
                valid_topics = [
                    "ğŸª æ˜Ÿç›˜è§£æ", "ğŸŒ  å®«ä½èƒ½é‡", "ğŸ”„ å½“å‰è¡Œè¿", 
                    "ğŸŒˆ å…ƒç´ å¹³è¡¡", "âœ¨ æ˜Ÿåº§å¹´è¿"
                ]
            else:
                # Fallback to generic topics
                valid_topics = ["æ€§æ ¼ç‰¹ç‚¹", "äº‹ä¸šè´¢è¿", "æ„Ÿæƒ…å§»ç¼˜", "å¥åº·æç¤º", "å¤§è¿æµå¹´"]
                
            # Always add chat option regardless of the system
            valid_topics.append("ğŸ’¬ ä¸éœ„å èŠå¤©")
        
        # Display menu with freshly generated topics list
        display_topic_menu(valid_topics)
        
        try:
            choice = input(f"\n{Colors.BOLD}è¯·é€‰æ‹© (0-{len(valid_topics)}): {Colors.ENDC}")
            if choice.strip() == "0" or choice.strip().lower() == "q":
                print(f"\n{Colors.YELLOW}âœ¨ è§£è¯»å®Œæˆï¼Œæ„Ÿè°¢æ‚¨ä½¿ç”¨éœ„å å‘½ç†ç³»ç»Ÿ! âœ¨{Colors.ENDC}")
                return True  # Return to main menu
            
            topic_index = int(choice) - 1
            if 0 <= topic_index < len(valid_topics):
                selected_topic = valid_topics[topic_index]
                
                # Special case for chat mode
                if "èŠå¤©" in selected_topic or "ğŸ’¬" in selected_topic:
                    return run_chat_mode(fortune_teller)
                
                # Show loading animation for regular topics
                animation = LoadingAnimation(f"æ­£åœ¨æ·±å…¥åˆ†æã€Œ{selected_topic}ã€")
                animation.start()
                
                try:
                    # This is where we'll replace direct method call with streaming approach
                    # First, create system and user prompts
                    system_name = fortune_teller._last_processed_data["system_name"]
                    processed_data = fortune_teller._last_processed_data["processed_data"]
                    
                    # Get clean topic name (remove emoji if present)
                    clean_topic = selected_topic
                    if any(emoji in selected_topic for emoji in ["ğŸ§ ", "ğŸ’¼", "â¤ï¸", "ğŸ§˜", "ğŸ”„", "ğŸŒŸ", "ğŸš¶", "ğŸ§­", "ğŸ›¤ï¸", "ğŸ’«", "ğŸª", "ğŸŒ ", "ğŸŒˆ", "âœ¨", "ğŸ’¬"]):
                        clean_topic = selected_topic[2:].strip()  # Remove emoji and whitespace
                    
                    # Define system-specific topics and prompts
                    if system_name == "bazi":
                        valid_topics = {
                            "ğŸ§  æ€§æ ¼å‘½æ ¼": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„æ€§æ ¼ç‰¹ç‚¹ã€æ‰èƒ½å€¾å‘å’Œè¡Œä¸ºæ¨¡å¼ï¼Œä½¿ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ¯”å–»å’Œä¾‹å­ã€‚",
                            "ğŸ’¼ äº‹ä¸šè´¢è¿": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„äº‹ä¸šå‘å±•ã€é€‚åˆè¡Œä¸šå’Œè´¢å¯Œæœºé‡ï¼Œç”¨é£è¶£å¹½é»˜çš„æ–¹å¼ç»™å‡ºå…·ä½“å»ºè®®ã€‚", 
                            "â¤ï¸ å©šå§»æƒ…æ„Ÿ": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„æ„Ÿæƒ…çŠ¶å†µã€å©šå§»å€¾å‘å’Œæ¡ƒèŠ±è¿åŠ¿ï¼Œä»¥è¯™è°ä½†ä¸æ²¹è…»çš„æ–¹å¼æä¾›è§è§£ã€‚",
                            "ğŸ§˜ å¥åº·å¯¿å…ƒ": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººçš„å¥åº·çŠ¶å†µã€æ½œåœ¨é—®é¢˜å’Œå…»ç”Ÿå»ºè®®ï¼Œç”¨è½»æ¾æ–¹å¼ç‚¹å‡ºéœ€è¦æ³¨æ„çš„åœ°æ–¹ã€‚",
                            "ğŸ”„ æµå¹´å¤§è¿": "è¯·è¯¦ç»†åˆ†ææ­¤å…«å­—ä¸»äººè¿‘æœŸå’Œæœªæ¥çš„è¿åŠ¿å˜åŒ–ã€å…³é”®æ—¶é—´ç‚¹ï¼Œç¥ç§˜è€Œåˆä¸å¤±é£è¶£åœ°å±•æœ›æœªæ¥ã€‚"
                        }
                    elif system_name == "tarot":
                        valid_topics = {
                            "ğŸŒŸ æ ¸å¿ƒå¯ç¤º": "è¯·è¯¦ç»†åˆ†ææ­¤å¡”ç½—ç‰Œé˜µçš„æ ¸å¿ƒä¿¡æ¯å’Œä¸»è¦å¯ç¤ºï¼Œç”¨æ·±å…¥è€Œé€šä¿—çš„è¯­è¨€æ­ç¤ºå…³é”®æ´è§ã€‚",
                            "ğŸš¶ å½“å‰å¤„å¢ƒ": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…ç›®å‰æ‰€å¤„çš„çŠ¶å†µã€é¢ä¸´çš„ç¯å¢ƒå’Œå¿ƒç†çŠ¶æ€ï¼Œç”¨ç”ŸåŠ¨çš„æ¯”å–»å¸®åŠ©ç†è§£ã€‚", 
                            "ğŸ§­ é˜»ç¢ä¸åŠ©åŠ›": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…å½“å‰é¢ä¸´çš„æŒ‘æˆ˜å’Œå¯åˆ©ç”¨çš„èµ„æºï¼Œæä¾›åˆ›é€ æ€§çš„æ€è·¯å’Œå®ç”¨å»ºè®®ã€‚",
                            "ğŸ›¤ï¸ æ½œåœ¨è·¯å¾„": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…å¯èƒ½çš„å‘å±•æ–¹å‘å’Œé€‰æ‹©å»ºè®®ï¼Œä»¥æ¸©å’Œä½†æ˜ç¡®çš„æ–¹å¼æŒ‡å‡ºå„ç§å¯èƒ½æ€§ã€‚",
                            "ğŸ’« ç²¾ç¥æˆé•¿": "è¯·è¯¦ç»†åˆ†ææ±‚æµ‹è€…çš„å†…åœ¨æˆé•¿å’Œä¸ªäººè½¬å˜çš„æœºä¼šï¼Œç”¨å¯å‘æ€§çš„æ–¹å¼é¼“åŠ±è‡ªæˆ‘æ¢ç´¢ã€‚"
                        }
                    elif system_name == "zodiac":
                        valid_topics = {
                            "ğŸª æ˜Ÿç›˜è§£æ": "è¯·è¯¦ç»†åˆ†æè¿™ä»½æ˜Ÿç›˜çš„æ•´ä½“ç‰¹ç‚¹ã€è¡Œæ˜Ÿè§’åº¦åŠä¸»è¦å½±å“ï¼Œç”¨æ¸…æ™°æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šå¤æ‚çš„æ˜Ÿè±¡å…³ç³»ã€‚",
                            "ğŸŒ  å®«ä½èƒ½é‡": "è¯·è¯¦ç»†åˆ†ææ˜Ÿç›˜ä¸­é‡è¦å®«ä½çš„èƒ½é‡åˆ†å¸ƒå’Œå½±å“ï¼Œç‰¹åˆ«å…³æ³¨ä¸Šå‡ã€ä¸­å¤©ã€ä¸‹é™å’Œå¤©åº•å®«ã€‚", 
                            "ğŸ”„ å½“å‰è¡Œè¿": "è¯·è¯¦ç»†åˆ†æå½“å‰è¡Œæ˜Ÿè¿è¡Œå¯¹æ±‚æµ‹è€…çš„å½±å“ï¼ŒæŒ‡å‡ºå…³é”®çš„è¡Œæ˜Ÿç›¸ä½å’Œè¿‡å¢ƒç°è±¡ã€‚",
                            "ğŸŒˆ å…ƒç´ å¹³è¡¡": "è¯·è¯¦ç»†åˆ†ææ˜Ÿç›˜ä¸­çš„å…ƒç´ ä¸èƒ½é‡åˆ†å¸ƒï¼Œè¯´æ˜ç«ã€åœŸã€é£ã€æ°´å››å…ƒç´ çš„å¹³è¡¡çŠ¶æ€ä¸ç¼ºå¤±æƒ…å†µã€‚",
                            "âœ¨ æ˜Ÿåº§å¹´è¿": "è¯·è¯¦ç»†é¢„æµ‹æœªæ¥ä¸€å¹´å†…çš„æ˜Ÿè±¡å˜åŒ–åŠå…¶å¯¹æ±‚æµ‹è€…çš„å½±å“ï¼Œç”¨é¼“èˆäººå¿ƒçš„æ–¹å¼å±•æœ›æœªæ¥æœºé‡ã€‚"
                        }
                    else:
                        # Default topics for any other system or fallback
                        valid_topics = {
                            "æ€§æ ¼ç‰¹ç‚¹": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„æ€§æ ¼ç‰¹ç‚¹ã€æ‰èƒ½å€¾å‘å’Œè¡Œä¸ºæ¨¡å¼ï¼Œä½¿ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ¯”å–»å’Œä¾‹å­ã€‚",
                            "äº‹ä¸šè´¢è¿": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„äº‹ä¸šå‘å±•ã€é€‚åˆè¡Œä¸šå’Œè´¢å¯Œæœºé‡ï¼Œç”¨é£è¶£å¹½é»˜çš„æ–¹å¼ç»™å‡ºå…·ä½“å»ºè®®ã€‚", 
                            "æ„Ÿæƒ…å§»ç¼˜": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„æ„Ÿæƒ…çŠ¶å†µã€å©šå§»å€¾å‘å’Œæ¡ƒèŠ±è¿åŠ¿ï¼Œä»¥è¯™è°ä½†ä¸æ²¹è…»çš„æ–¹å¼æä¾›è§è§£ã€‚",
                            "å¥åº·æç¤º": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººçš„å¥åº·çŠ¶å†µã€æ½œåœ¨é—®é¢˜å’Œå…»ç”Ÿå»ºè®®ï¼Œç”¨è½»æ¾æ–¹å¼ç‚¹å‡ºéœ€è¦æ³¨æ„çš„åœ°æ–¹ã€‚",
                            "å¤§è¿æµå¹´": "è¯·è¯¦ç»†åˆ†ææ­¤å‘½ç›˜ä¸»äººè¿‘æœŸå’Œæœªæ¥çš„è¿åŠ¿å˜åŒ–ã€å…³é”®æ—¶é—´ç‚¹ï¼Œç¥ç§˜è€Œåˆä¸å¤±é£è¶£åœ°å±•æœ›æœªæ¥ã€‚"
                        }
                    
                    # Make sure the selected topic is in our topics dictionary to avoid KeyError
                    topic_description = ""
                    try:
                        topic_description = valid_topics.get(selected_topic, "")
                        logger.info(f"æ‰¾åˆ°è¯é¢˜'{selected_topic}'çš„æè¿°: {topic_description}")
                    except Exception as e:
                        logger.error(f"è·å–è¯é¢˜æè¿°æ—¶å‡ºé”™: {e}", exc_info=True)
                        # Provide a generic description if we can't find one
                        topic_description = f"è¯·è¯¦ç»†åˆ†æ{clean_topic}æ–¹é¢çš„ä¿¡æ¯ï¼Œç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€æä¾›æœ‰è§è§£çš„è§£è¯»ã€‚"
                        
                    # Create system prompts for different fortune systems
                    if system_name == "bazi":
                        system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½æ¥è‡ªä¸­å›½çš„å…«å­—å‘½ç†å­¦å¤§å¸ˆï¼Œå·²æœ‰30å¹´çš„å åœç»éªŒï¼Œæ€§æ ¼é£è¶£å¹½é»˜åˆä¸å¤±æ™ºæ…§ã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„å…«å­—å‘½ç†åˆ†æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{topic_description}

è¯·ç¡®ä¿ä½ çš„å›ç­”æ—¢ä¸“ä¸šåˆé£è¶£ï¼Œåƒä¸€ä½å’Œè”¼å¯äº²çš„é•¿è¾ˆèŠå¤©ï¼Œè€Œä¸æ˜¯å†·å†°å†°çš„è¯´æ•™ã€‚è®©æ±‚æµ‹è€…æ„Ÿåˆ°è½»æ¾æ„‰å¿«ï¼ŒåŒæ—¶è·å¾—æœ‰ä»·å€¼çš„äººç”Ÿå¯ç¤ºã€‚

ä½ çš„åˆ†æåº”æ—¢æœ‰ä¸“ä¸šæ°´å‡†ï¼Œåˆå¯Œå«æƒ…è¶£ä»·å€¼ï¼Œå¯ä»¥å·§å¦™åœ°å¼•ç”¨ä¸€äº›è°šè¯­ã€å…¸æ•…æˆ–ç”Ÿæ´»å°æ•…äº‹æ¥å¸®åŠ©ç†è§£ã€‚
"""
                    elif system_name == "tarot":
                        system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½ç²¾é€šå¡”ç½—ç‰Œè§£è¯»çš„å¤§å¸ˆï¼Œæ‹¥æœ‰æ·±åšçš„ç¥ç§˜å­¦çŸ¥è¯†å’Œ20å¹´çš„å¡”ç½—ç‰Œè§£è¯»ç»éªŒã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„å¡”ç½—ç‰Œé˜µè§£æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[selected_topic]}

ä½ çš„é£æ ¼ç¿æ™ºè€Œç¥ç§˜ï¼Œå……æ»¡ç€æ™ºæ…§ä¸æ´å¯ŸåŠ›ï¼Œä½†åŒæ—¶ä¹Ÿå¾ˆäº²å’Œï¼Œèƒ½ç”¨ç”ŸåŠ¨çš„è¯­è¨€å°†å¤æ‚çš„ç¬¦å·è±¡å¾è½¬åŒ–ä¸ºç›´è§‚çš„ç†è§£ã€‚

ä½ çš„è§£è¯»åº”å½“æ—¢æœ‰ä¸“ä¸šæ·±åº¦ï¼Œåˆæœ‰çµæ€§å¯å‘ï¼Œå¯ä»¥é€‚å½“å¼•ç”¨ä¸€äº›ç¥è¯ã€ä¼ è¯´æˆ–è±¡å¾å­¦çŸ¥è¯†æ¥ä¸°å¯Œåˆ†æã€‚
"""
                    elif system_name == "zodiac":
                        system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½ç²¾é€šè¥¿æ–¹å æ˜Ÿå­¦çš„ä¸“å®¶ï¼Œæœ‰ç€ä¸°å¯Œçš„å æ˜Ÿå’¨è¯¢ç»éªŒã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„æ˜Ÿç›˜åˆ†æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[selected_topic]}

ä½ çš„é£æ ¼æ—¢æœ‰ä¸“ä¸šæ·±åº¦ï¼Œåˆä¸ä¹å¹½é»˜æ„Ÿï¼Œèƒ½å¤Ÿç”¨ç”ŸåŠ¨çš„æ¯”å–»å’Œå®ä¾‹è§£é‡Šå¤æ‚çš„æ˜Ÿè±¡ã€‚ä½ æ—¢å°Šé‡å æ˜Ÿå­¦çš„ä¼ ç»ŸçŸ¥è¯†ï¼Œ
åˆä¸ä¼šå®Œå…¨å†³å®šè®ºï¼Œè€Œæ˜¯å¼ºè°ƒæ¯ä¸ªäººéƒ½æœ‰è‡ªç”±æ„å¿—æ¥é€‰æ‹©å¦‚ä½•åº”å¯¹æ˜Ÿè±¡å½±å“ã€‚

ä½ çš„è§£è¯»åº”å½“å¹³è¡¡ã€å®¢è§‚ï¼Œé¿å…è¿‡äºç»å¯¹åŒ–çš„é¢„æµ‹ã€‚æä¾›å®ç”¨çš„å»ºè®®å’Œè§‚ç‚¹ï¼Œå¸®åŠ©å’¨è¯¢è€…æ›´å¥½åœ°ç†è§£è‡ªå·±å’Œå½“å‰çš„èƒ½é‡å½±å“ã€‚
"""
                    else:
                        # Default generic prompt
                        system_prompt = f"""ä½ æ˜¯"éœ„å "ï¼Œä¸€ä½æ¥è‡ªä¸­å›½çš„å‘½ç†å­¦å¤§å¸ˆï¼Œå·²æœ‰30å¹´çš„å åœç»éªŒï¼Œæ€§æ ¼é£è¶£å¹½é»˜åˆä¸å¤±æ™ºæ…§ã€‚
ä½ åˆšåˆšä¸ºæ±‚æµ‹è€…æä¾›äº†åŸºæœ¬çš„å‘½ç†åˆ†æã€‚ç°åœ¨ï¼Œæ±‚æµ‹è€…æƒ³äº†è§£æ›´å¤šå…³äº"{clean_topic}"çš„è¯¦ç»†ä¿¡æ¯ã€‚

è¯·ä¸ºæ±‚æµ‹è€…æä¾›å…³äº"{clean_topic}"çš„æ·±å…¥è¯¦å°½çš„è§£è¯»ã€‚{valid_topics[selected_topic]}

è¯·ç¡®ä¿ä½ çš„å›ç­”æ—¢ä¸“ä¸šåˆé£è¶£ï¼Œåƒä¸€ä½å’Œè”¼å¯äº²çš„é•¿è¾ˆèŠå¤©ï¼Œè€Œä¸æ˜¯å†·å†°å†°çš„è¯´æ•™ã€‚è®©æ±‚æµ‹è€…æ„Ÿåˆ°è½»æ¾æ„‰å¿«ï¼ŒåŒæ—¶è·å¾—æœ‰ä»·å€¼çš„äººç”Ÿå¯ç¤ºã€‚

ä½ çš„åˆ†æåº”æ—¢æœ‰ä¸“ä¸šæ°´å‡†ï¼Œåˆå¯Œå«æƒ…è¶£ä»·å€¼ï¼Œå¯ä»¥å·§å¦™åœ°å¼•ç”¨ä¸€äº›è°šè¯­ã€å…¸æ•…æˆ–ç”Ÿæ´»å°æ•…äº‹æ¥å¸®åŠ©ç†è§£ã€‚
"""
                    
                    # Create user prompts based on system type
                    if system_name == "bazi":
                        user_prompt = f"""åŸºäºåˆšæ‰çš„å…«å­—åˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚

å››æŸ±å…«å­—ï¼š
{processed_data["four_pillars"]["year"]} {processed_data["four_pillars"]["month"]} {processed_data["four_pillars"]["day"]} {processed_data["four_pillars"]["hour"]}

æ€§åˆ«: {processed_data["gender"]}
å‡ºç”Ÿæ—¥æœŸ: {processed_data["birth_date"]}
å‡ºç”Ÿæ—¶é—´: {processed_data["birth_time"]}

æ—¥ä¸»: {processed_data["day_master"]["character"]} ({processed_data["day_master"]["element"]})
æœ€å¼ºäº”è¡Œ: {processed_data["elements"]["strongest"]}
æœ€å¼±äº”è¡Œ: {processed_data["elements"]["weakest"]}

è¯·æä¾›è¯¦ç»†è€Œæœ‰è¶£çš„"{clean_topic}"åˆ†æã€‚"""
                    elif system_name == "tarot":
                        # Reconstruct tarot reading summary from processed data
                        card_info = ""
                        if "reading" in processed_data:
                            for i, card in enumerate(processed_data["reading"], 1):
                                position = card.get("position", f"ä½ç½®{i}")
                                card_name = card.get("card", "")
                                orientation = card.get("orientation", "")
                                card_info += f"{position}: {card_name} ({orientation})\n"
                        
                        user_prompt = f"""åŸºäºåˆšæ‰çš„å¡”ç½—ç‰Œé˜µåˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚

å¡”ç½—ç‰Œé˜µï¼š{processed_data.get("spread", {}).get("name", "æœªçŸ¥ç‰Œé˜µ")}
é—®é¢˜ï¼š{processed_data.get("question", "æœªçŸ¥")}
é¢†åŸŸï¼š{processed_data.get("focus_area", "æœªçŸ¥")}

æŠ½å–çš„ç‰Œï¼š
{card_info}

è¯·æä¾›è¯¦ç»†è€Œæœ‰æ·±åº¦çš„"{clean_topic}"åˆ†æã€‚"""
                    elif system_name == "zodiac":
                        # Construct zodiac reading summary from processed data
                        sign_info = processed_data.get("zodiac_sign", {})
                        
                        user_prompt = f"""åŸºäºåˆšæ‰çš„æ˜Ÿç›˜åˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚

å¤ªé˜³æ˜Ÿåº§ï¼š{sign_info.get("name", "æœªçŸ¥")} ({sign_info.get("english", "Unknown")})
æœˆäº®æ˜Ÿåº§ï¼š{processed_data.get("moon_sign", "æœªçŸ¥")}
ä¸Šå‡æ˜Ÿåº§ï¼š{processed_data.get("rising_sign", "æœªçŸ¥")}

å…ƒç´ ï¼š{sign_info.get("element", "æœªçŸ¥")}
å“è´¨ï¼š{sign_info.get("quality", "æœªçŸ¥")}
ä¸»å®°æ˜Ÿï¼š{sign_info.get("ruler", "æœªçŸ¥")}

å…³æ³¨é¢†åŸŸï¼š{processed_data.get("question_area", "æœªçŸ¥")}

è¯·æä¾›è¯¦ç»†è€Œæœ‰æ´è§çš„"{clean_topic}"åˆ†æã€‚"""
                    else:
                        # Generic prompt as fallback
                        user_prompt = f"""åŸºäºåˆšæ‰çš„å‘½ç†åˆ†æï¼Œè¯·è¯¦ç»†è§£è¯»"{clean_topic}"æ–¹é¢çš„ä¿¡æ¯ã€‚
                        
è¯·æä¾›è¯¦ç»†è€Œæœ‰ä¸“ä¸šçš„"{clean_topic}"åˆ†æã€‚"""
                    
                    def handle_followup_streaming(response_generator, start_time, thinking_anim=None):
                        """è¯é¢˜è§£è¯»æµå¼è¾“å‡ºå¤„ç†å‡½æ•°"""
                        nonlocal animation
                        # åœæ­¢ä¸»åŠ è½½åŠ¨ç”»
                        animation.stop()
                        
                        # å¦‚æœæœ‰æ€è€ƒåŠ¨ç”»ï¼Œåœæ­¢å®ƒ
                        if thinking_anim:
                            thinking_anim.stop()
                        
                        # ä½¿ç”¨æµå¼è¾“å‡ºå±•ç¤ºç»“æœ
                        return print_followup_result_streaming(
                            selected_topic,
                            response_generator
                        )
                    
                    def handle_followup_standard(response, metadata, thinking_anim=None):
                        """è¯é¢˜è§£è¯»æ ‡å‡†è¾“å‡ºå¤„ç†å‡½æ•°"""
                        nonlocal animation
                        
                        # åœæ­¢åŠ è½½åŠ¨ç”»
                        animation.stop()
                        
                        # å¦‚æœæœ‰æ€è€ƒåŠ¨ç”»ï¼Œä¹Ÿåœæ­¢å®ƒ
                        if thinking_anim:
                            thinking_anim.stop()
                        
                        # ä½¿ç”¨æ ‡å‡†æ–¹å¼æ˜¾ç¤ºç»“æœ
                        print_followup_result(selected_topic, response)
                        return response
                    
                    # Import and setup thinking animation
                    from fortune_teller.ui.thinking_animation import ChatThinkingAnimation
                    
                    # å…ˆå®Œå…¨åœæ­¢ä¸»åŠ¨ç”»ï¼Œç¡®ä¿å®ƒä¸å†æ˜¾ç¤ºä»»ä½•å†…å®¹
                    animation.stop()
                    
                    # æ¸…é™¤ç°æœ‰è¾“å‡ºè¡Œï¼Œç¡®ä¿æ²¡æœ‰æ®‹ç•™åŠ¨ç”»æ–‡æœ¬
                    sys.stdout.write("\r" + " " * 60 + "\r") 
                    sys.stdout.flush()
                    
                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿ä¸»åŠ¨ç”»å®Œå…¨åœæ­¢
                    time.sleep(0.1)
                    
                    # æ˜¾ç¤ºå³æ—¶åé¦ˆï¼ˆåœ¨APIè°ƒç”¨å‰ï¼‰
                    thinking_animation = ChatThinkingAnimation(prefix="")
                    print(f"\n{Colors.GREEN}è§£è¯»ä¸­: {Colors.ENDC}", end="", flush=True)
                    thinking_animation.start()
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„APIç”Ÿæˆå“åº”
                    response = fortune_teller.llm_connector.generate_best_response(
                        system_prompt, 
                        user_prompt,
                        streaming_handler=lambda gen, st: handle_followup_streaming(gen, st, thinking_animation),
                        non_streaming_handler=lambda resp, meta: handle_followup_standard(resp, meta, thinking_animation)
                    )
                    
                except Exception as e:
                    animation.stop()
                    print(f"\n{Colors.RED}è§£è¯»å‡ºé”™: {e}{Colors.ENDC}")
            else:
                print(f"{Colors.YELLOW}è¯·è¾“å…¥æœ‰æ•ˆçš„é€‰é¡¹ (0-{len(valid_topics)}){Colors.ENDC}")
        except ValueError:
            print(f"{Colors.YELLOW}è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—{Colors.ENDC}")
        except KeyboardInterrupt:
            print(f"\n{Colors.YELLOW}âœ¨ å·²å–æ¶ˆæ·±å…¥è§£è¯»ï¼Œæ„Ÿè°¢æ‚¨ä½¿ç”¨éœ„å å‘½ç†ç³»ç»Ÿ! âœ¨{Colors.ENDC}")
            return True  # Return to main menu
    
    return True


def main():
    """Main entry point for the Fortune Teller application."""
    parser = argparse.ArgumentParser(
        description="éœ„å  (Fortune Teller) - åŸºäºLLMçš„å¤šç³»ç»Ÿç®—å‘½ç¨‹åº"
    )
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºå¯ç”¨çš„å åœç³»ç»Ÿ")
    parser.add_argument("--system", help="ä½¿ç”¨æŒ‡å®šçš„å åœç³»ç»Ÿ")
    parser.add_argument("--output", help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")
    
    args = parser.parse_args()
    
    # Configure console logging if verbose mode is enabled
    if args.verbose:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        logging.getLogger().addHandler(console_handler)
    
    try:
        # Show initialization message
        print(f"{Colors.CYAN}æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...{Colors.ENDC}")
        
        # Initialize the application
        fortune_teller = FortuneTeller(args.config)
        
        # Show LLM information
        llm_config = fortune_teller.config_manager.get_config("llm")
        print_llm_info(llm_config)
        
        if args.list:
            # Just list available systems and exit
            print_available_systems(fortune_teller.get_available_systems())
            return
        
        # Run the interactive menu
        run_interactive_menu(fortune_teller, args)
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()
